
#Refresher before jumping in 

  # Comments use "#"
  # Int = whole number, Float = decimal
  # None = special datatype (ex: when you have 3 rows and the second one is blank)
  # Operators (PEMDAS) +,*,/,-,% (remainder), //(round down division), == (Boolean), !=
  # Var= Subject to change (age = 29)
  # Built in Functions (EX: str(),int(),type(), etc.)
  # Custom Functions: def = define, parameters = name we grant to an input of a function, return = what we want out of the code
  # str: Imutable = incapable of change, mutable = capable of change, str is imutable, in = is the item on the left in the right text
  # Lists: mutable data structure that holds collection of elements, append() = adds to list, pop() = removes last item in list
  # index positions and slicing: index of any word is -1 of len, [1:3] - never pulls the last number,left side: starts with 0 when counting, going backwards: start with -1
  # Dictionary an unordered collection of key-values pairs {}, dictionary_name{key being added: value being added, etc}, pop(key) = returns value but also removes pair from dictionary, dictionary.Values(shows values in your dictionary)
  

############SECTION 1
  
#Series - One Dimensional Array

    # Series object from a python list
    
    ice_cream = ["Chocolate", "Vanilla", "Strawberry", "Rum Raisin"]
    
    # Series is a class which is a blueprint for an obeject
    
    pd.Series(ice_cream)
    
    # produces list with index along with "dtype: object"
      
    lottery = [4, 8, 15, 16, 23, 42]
    pd.Series(lottery)
    
    # produces same list but difference is dtype now says int64 (64 is the bytes in your computer
    
    registrations = [True, False, False, False, True]
    pd.Series(registrations
    
        
    
    #Series object from a python dictionary
  
    sushi = {
      "Salmon": "Orange",
      "Tuna": "Red",
      "Eel": "Brown"
    }

    pd.Series(sushi)
    
    # produces dictionary with no index, but has dtype 
    
    
    # Excercise 8
    
        # Import the pandas library and assign it its "pd" alias
        
        import pandas as pd
        
        # Create a list with 4 countries - United States, France, Germany, Italy
        # Create a new Series by passing in the list of countries
        # Assign the Series to a "countries" variable

        countries = pd.Series(["United States", "France", "Germany", "Italy"])

        # Create a list with 3 colors - red, green, blue
        # Create a new Series by passing in the list of colors
        # Assign the Series to a "colors" variable
        
        colors = pd.Series(["red", "green", "blue"])

        # Given the "recipe" dictionary below,
        # create a new Series by passing in the dictionary as the data source
        # Assign the resulting Series to a "series_dict" variable
        
        recipe = {
           "Flour": True,
           "Sugar": True,
           "Salt": False
        }
        
        series_dict = pd.Series(recipe)
   
    
    
    
    
 # Methods & Attributes
 
     # Method = a command pd can perform for us EX: "hello".upper()
     
     prices = pd.Series([2.99, 4.45, 1.36])
     prices
     
     prices.sum()
     prices.product()
     prices.mean()
     
     # Attributes - detail, characteristic or fact that an object can tell about itself
     # Method is a command, attribute tells us what it is. EX: Car: Method is drive while color is attribute
     
     adjectives = pd.Series(["Smart", "Handsome", "Charming", "Brilliant", "Humble"])
     adjectives
     
     # size = tells you how many elements
     adjectives.size
     
     # is_unique = boolean that tells if everything is different
     adjectives.is_unique
     
     adjectives.values
     adjectives.index
     adjectives.dtype
     
     # Excercise 9
     
         import pandas as pd

         # The Series below stores the number of home runs
         # that a baseball player hit per game
         
         home_runs = pd.Series([3, 4, 8, 2])

         # Find the total number of home runs (i.e. the sum) and assign it
         # to the total_home_runs variable below

         total_home_runs = home_runs.sum()

         # Find the average number of home runs and assign it
         # to the average_home_runs variable below
         
         average_home_runs = home_runs.mean()
   
   
   
# Parameters & Arguements
    
    # Paramter - The name we give to an expected input
    # Arguement - The concrete value that we provide to a parameter
    # Video Game Difficulty - Easy, Medium, Hard : Parameter = Difficulty, Arguement = Easy, Medium, Hard
    
    fruits = ["Apples", "Orange", "Plum", "Grape", "Blueberry")
    weekdays = ["Monday", "Tuesday", "Wednesday", "Thursday", "Fridays"]
    
    # Puts a list but instead of numbers in a list, it's now the weekdays. So it will say Monday Apple in the first line
    # Position is below while Key is data and index
    pd.Series(fruits, weekdays)
    
    # These below produce the same list because the data and index are associated in pd
    pd.Series(data = fruits, index = weekdays)
    pd.Series(index = weekdays, data = fruits)
    pd.Series(fruits, index = weekdays)
    
    # Can have duplicate labels
    
    # Excercise 10 
    
        # If you see a test failure when checking your solution,
        # note that [left] refers to YOUR code while [right]
        # refers to the correct code that the computer is comparing
        # to your work

        # The code below defines a list of delicious foods
        # and some dipping sauces to dip them in
        import pandas as pd

        foods = ["French Fries", "Chicken Nuggets", "Celery", "Carrots"]
        dipping_sauces = ["BBQ", "Honey Mustard", "Ranch", "Sriracha"]

        # Create a Series and assign it to the s1 variable below. 
        # Assign the foods list as the data source
        # and the dipping_sauces list as the Series index 
        # For this solution, use positional arguments (i.e. feed in the arguments sequentially)
        
        s1 = pd.Series(foods, dipping_sauces)
        
        # Create a Series and assign it to the s2 variable below. 
        # Assign the dipping_sauces list as the data source
        # and the foods list as the Series index 
        # For this solution, use keyword arguments (i.e. provide the parameter names
        # alongside the arguments)
        s2 = pd.Series(data = dipping_sauces, index = foods)




# Import Series with the pd.read_csv Function
    
    # NOTE - Save the file in the same place or you need to create path
    #Running the below creates a dataframe which is pds = of a table
    pd.read_csv("pokemon.csv")
    
    # Moving this into a Series object
    # usecols = which column you want
    # squeeze = moves it from a dataframe into a series obj
    pokemon = pd.read_csv("pokemon.csv", usecols = ["Pokemon"]).squeeze("columns")
    pokemon
    
    # Google Stock Price
    google = pd.read_csv("google_stock_price.csv", usecols = ["Stock Price"]).squeeze("columns")
    google
    
    
    # Excercise 11
    
    
        # If you see a test failure when checking your solution,
        # note that [left] refers to YOUR code while [right]
        # refers to the correct code that the computer is comparing
        # to your work

        import pandas as pd

        # We have a foods.csv CSV file with 3 columns: Item Number, Menu Item, Price
        # You can explore the data by clicking into the foods.csv file on the left
        # Import the CSV file into a pandas Series object
        # The Series should have the standard pandas numeric index
        # The Series values should be the string values from the "Menu Item" column
        # Assign the Series object to a "foods" variable
        
        foods = pd.read_csv("foods.csv", usecols = ["Menu Item"]).squeeze("columns")
 
 
 
 # Head and Tail Methods

    # Both return a specified number of rows from a series
    
    google = pd.read_csv("google_stock_price.csv", usecols = ["Stock Price"]).squeeze("columns")
    pokemon = pd.read_csv("pokemon.csv", usecols = ["Pokemon"]).squeeze("columns")
    
    # Heads returns first 5 rows
    pokemon.head()
    pokemon.head(5)
    pokemon.head(n = 5)

    # Tail returns first 5 rows
    pokemon.tail()
    pokemon.tail(5)
    pokemon.tail(n = 5)
    
    # Excercise 12
    
    
        # If you see a test failure when checking your solution,
        # note that [left] refers to YOUR code while [right]
        # refers to the correct code that the computer is comparing
        # to your work

        import pandas as pd

        # We have a roller_coasters.csv CSV file with 4 columns: Name, Park, Country, and Height.
        # You can explore the data by clicking into the CSV file on the left
        # Import the CSV file into a pandas Series object
        # The Series should have the standard pandas numeric index
        # The Series values should be the string values from the "Name" column
        # Assign the Series object to a "coasters" variable

        coasters = pd.read_csv("roller_coasters.csv", usecols = ["Name"]).squeeze("columns")

        # I only want to ride the top 3 roller coasters on the list.
        # Starting with the "coasters" Series, extract the first 3 rows in a new Series.
        # Assign the new Series to a "top_three" variable.

        top_three = coasters.head(3)

        # I'm now curious about some of the last entries on the coaster list.
        # Starting with the "coasters" Series, extract the last 4 rows in a new Series.
        # Assign the new Series to a "bottom_four" variable.
    
        bottom_four = coasters.tail(4)
    
    
    
# Passing Series to Python's Built-In Functions & sort_values method

    google = pd.read_csv("google_stock_price.csv", usecols = ["Stock Price"]).squeeze("columns")
    pokemon = pd.read_csv("pokemon.csv", usecols = ["Pokemon"]).squeeze("columns")
    
    # dir = lets you know list of attributes available with that object
    dir(pokemon)
    
    # sorted = sorts the list
    sorted(pokemon)
    
    #dict = key and values of the list
    dict(pokemon)
    
    # Max and Min = Max returns last item in alphabet and min does first
    max(pokemon)
    min(pokemon)
    
    #sort_values - default ascending alphabet, lowest number
    pokemon.sort_values()
    
    # Excercise 13
    
    
        # Below, we have a list of delicious tortilla chip flavors
        flavors = ["Spicy Sweet Chili", "Cool Ranch", "Nacho Cheese", "Salsa Verde"]

        # Create a new Series object, passing in the flavors list defined above
        # Assign it to a 'doritos' variable. The resulting Series should look like this:
        #
        #
        #   0    Spicy Sweet Chili
        #   1           Cool Ranch
        #   2         Nacho Cheese
        #   3          Salsa Verde
        #   dtype: object

        doritos = pd.Series(flavors)


        # Below, sort the doritos Series in descending order.
        # Assign the sorted a Series to a 'sorted_doritos' variable.
        # The sorted Series should like this:
        #
        #   0    Spicy Sweet Chili
        #   3          Salsa Verde
        #   2         Nacho Cheese
        #   1           Cool Ranch
        #   dtype: object

        sorted_doritos = doritos.sort_values(ascending = False)
        
     
     
# The sort_index Method
     
    # Same as before but with an index
    pd.read_csv("pokemon", index_col = "Pokemon").squeeze()
    pokemon.sort_index()
 
        
    # Excercise 14
    
    
        # If you see a test failure when checking your solution,
        # note that [left] refers to YOUR code while [right]
        # refers to the correct code that the computer is comparing
        # to your work
         
        import pandas as pd

        # Below, we have a list of delicious drink flavors
        # We create a sorted Series of strings and assign it to a 'gatorade' variable
         
        flavors = ["Red", "Blue", "Green", "Orange"]
        gatorade = pd.Series(flavors).sort_values()

        # I'd like to return the Series to its original order        
        # (sorted by the numeric index in ascending order). 
        # Sort the gatorade Series by index
        # Assign the result to an 'original' variable.

        original = gatorade.sort_index(ascending = True)
        
        
        
    
 # Check for inclusion with Python's Keywords
  
     
     pokemon = pd.read_csv("pokemon", index_col = ["Pokemon"]).squeeze()
     pokemon.head()
     
     # pds doesn't look in index
     "Pikachu" in pokemon.values
     # Returns True
     
     # Excercise 15
    
    
         # If you see a test failure when checking your solution,
         # note that [left] refers to YOUR code while [right]
         # refers to the correct code that the computer is comparing
         # to your work
         
         import pandas as pd

         # This challenge includes a coffee.csv with 2 columns: 
         # Coffee and Calories. Import the CSV. Assign the Coffee
         # column to be the index and the Calories column to be the
         # Series' values. Assign the Series to a 'coffee' variable.

         coffee = pd.read_csv("coffee.csv", index_col = "Coffee").squeeze("columns")

         # Check whether the coffee 'Flat White' is present in the data.
         # Assign the result to a `flat_white` variable

         flat_white = "Flat White" in coffee.index

         # Check whether the coffee 'Cortado' is present in the data.
         # Assign the result to a `cortado` variable

         cortado = "Cortado" in coffee.index
         
         # Check whether the coffee 'Blackberry Mocha' is present in the data.
         # Assign the result to a `blackberry_mocha` variable

         blackberry_mocha = "Blackberry Mocha" in coffee.index

         # Check whether the value 221 is present in the data.
         # Assign the result to a 'high_calorie' variable.

         high_calorie = 221 in coffee.values

         # Check whether the value 400 is present in the data.
         # Assign the result to a 'super_high_calorie' variable.

         super_high_calorie = 400 in coffee.values
         
         
# Extract Series Values by Index Position and Label

    pokemon = pd.read_csv("pokemon", index_col = "Pokemon").squeeze()
    pokemon.head()
    
    # Return multiple items from the list
    pokemon[(100, 200, 300)]
    
    #27 would be INCLUDED while 35 is EXCLUDED
    pokemon[(27:35)]
    
    # Pull a label
    pokemon["Mewtwo"]
    pokemon[("Mewtwo", "Jolteon", "Meowth")]
        
        
    # Excercise 16
    
        import pandas as pd

        # I have a dictionary that maps guitar types to their colors
        guitars_dict = {
        "Fender Telecaster": "Baby Blue",
        "Gibson Les Paul": "Sunburst",
        "ESP Eclipse": "Dark Green"
        }

        # Create a new Series object, passing in the guitars_dict dictionary as the data source.
        # Assign the resulting Series to a "guitars" variable.

        guitars = pd.Series(guitars_dict)

        # Access the value for the index position of 0 within the "guitars" Series.
        # Assign the value to a "fender_color" variable.

        fender_color = guitars[0]

        # Access the value for the index label of "Gibson Les Paul" in the "guitars" Series.
        # Assign the value to a "gibson_color" variable.

        gibson_color = guitars["Gibson Les Paul"]

        # Access the value for the index label of "ESP Eclipse" in the "guitars" Series.
        # Assign the value to a "esp_color" variable.

        esp_color = guitars["ESP Eclipse"]
        
     
    
    
# Get Method, Overwrite a Series Value, Copy Method, the Inplace Parameter, Math Methods on Series objects
# Broadcasting, Use the value_counts Method to see Unique values within a series

    pokemon = pd.read_csv("pokemon", index_col = "Pokemon").squeeze()
    pokemon.head()
    
    # Both get same result which is Grass
    pokemon.get(0)
    pokemon.get("Bulbasaur")
    
    pokemon.get([5, 10])
    pokemon.get(["Moltress", Meowth"])
    
    # if get can't find it, returns None as default
    # You can make a return value different then None (see below)
    pokemon.get("Digimon", "Nonexistent")
    
    # Same for list and index
    pokemon.get(["Moltress", Meowth"], "Nonexistent")
    pokemon.get([0, 500, 10000], "Nonexistent")
    
    # Overwrite example 
    pokemon[0] = "Borisaur"
    
    # What if the line doesn't exist (adding line 1500 instead with only 721 lines)
    # Just adds this to the end 
    pokemon[1500] = "Hello"
    
    # Overwriting multiple
    pokemon([1, 2, 4]) = ["Firemon", "Flameon", "Blazemon"]
    
    # What about an index column
    pokemon = pd.read_csv("pokemon", index_col = "Pokemon").squeeze("columns")
    pokemon.head()
    
    pokemon["Bulbasaur"] = "Awesomeon"
    pokemon[1] = "Grassmon"
    
    # Copy Method
    # Series and dataframe would both be changed when doing it this way when we don't want to
    pokemon_df = pd.read_csv("pokemon.csv", usecols = ["Pokemon"])
    pokemon_series = pokemon_df.squeeze("columns")
    pokemon_series[0] = "Whatever"
    pokemon_df
    # big house = df
    #   Door
    #    Paint Red =
    # We change the door but technically means the house has changed
    
    #Make an independent series
    pokemon_df = pd.read_csv("pokemon.csv", usecols = ["Pokemon"])
    pokemon_series = pokemon_df.squeeze("columns").copy()
    
    # Inplace Parameter
    google = (pd.read_csv("google_stock_price.csv", usecols = ["Stock Price"]).squeeze("columns").copy())
    
    # Replacing/Overwrite the original google
    google = google.sort_values()
    
    # where inplace parameter comes into play for overwrite
    google.sort_values(inplace = True)
    google.sort_index(inplace = True)
    
    # Math Methods
    
    google = pd.read_csv("google_stock_price.csv", usecols = ["Stock Price"]).squeeze("columns")
    
    # Count() = counts number of non-null series, does 3012
    google.count()
    google.mean()
    google.sum()
    google.product()
    google.std()
    google.min()
    google.max()
    google.median()
    
    # Describe() = gives you a whole series of statical analysis
    google.describe()
    
    #Broadcasting
    
    google = pd.read_csv("google_stock_price.csv", usecols = ["Stock Price"]).squeeze("columns")
    
    # Adding 10 to every number in the Series
    google + 10
    
    # The value_counts Methods  - counts unique values (grass type pokemon are more than one)
    pokemon = pd.read_csv("pokemon", index_col = "Pokemon").squeeze("columns")
    # Grass type answer is 66
    pokemon.value_counts()
    # Normalize = gives you the percentage of total
    pokemon.value_counts(normalize = True)
    
            
    # Excercise 17
    
        import pandas as pd
        # We have a hot_dogs.csv CSV file with 2 columns: Year and Winner.
        # The dataset stores the winner of the world-famous Nathan's Hot Dog Eating
        # contest for each year since 1967. You can explore the data by clicking into 
        # the CSV file on the left.
        #
        # Import the CSV file into a pandas Series object
        # The Series should have the standard pandas numeric index
        # The Series values should be the string values from the "Winner" column
        # Assign the Series object to a "hot_dogs" variable

        hot_dogs = pd.read_csv("hot_dogs.csv", usecols = ["Winner"], squeeze = True)

        # I'm curious how many times each winner has won the hot dog-eating contest.
        # Create a new Series that shows each person's name (index labels) 
        # and the number of times they've won (the values). What method can
        # help you generate this Series?
        # Assign the Series to a "names_and_wins" variable.
    
        names_and_wins = hot_dogs.value_counts()
    
    
# The Apply and Map Method  
    
    pokemon = pd.read_csv("pokemon", index_col = "Pokemon").squeeze("columns")
    
    #Run the len function to every row in a Series
    
    pokemon.apply(len)
    
    def rank_pokemon(pokemon_type):
      if pokemon_type in ["Grass", "Fire", "Water"]:
       return "Classic"
      elif pokemon_type == "Normal":
        return "Boring"
      else: 
        return "TBD"
        
    pokemon.apply(rank_pokemon)
    
    # Map Method - connect or associate to something else. Accepts an object instead of a function
    
    pokemon = pd.read_csv("pokemon", index_col = "Pokemon").squeeze("columns")
    
    mappings = {
        "Grass": "Classic",
        "Fire": "Classic",
        "Water": "Classic",
        "Normal": "Boring"
    }
    
    pokemon.map(mappings)
    
    mapping_series = pd.Series(mappings)
    mapping_series
    pokemon.map(mappings_series)
    
    
    
    
############SECTION 2

# Dataframe - Has ROWS and columns. Needs two points for reference


    nba = pd.read_csv("nba.csv")
    # Methods and Attributes between Series and Dataframes
    # Have some similar traits
    
    # Differences between Shared Methods
    
    revenue =pd.read_csv("revenue.csv", index_col = "Date")
    revenue
    
    s = pd.Series ([1, 2, 3])
    s.sum()
    
    #Sums every column versus the s
    revenue.sum()
    revenue.sum(axis = "index")
    revenue.sum(axis = 0)
    
    
    # How to sum a row
    revenue.sum(axis = "columns")
    revenue.sum(axis = 1)
    
    # Select one column from a dataframe
    nba = pd.read_csv("nba.csv")
    nba
    
    # dataframe is just a bunch of series glued together that share a common index
    nba.Name 
    type{nba.Name}
    
    nba["Name"].head(7).values
    
    # Excercise 18
    
        import pandas as pd
        # This challenge includes a cruise_ships.csv with 4 columns: 
        # Name, Operator, Year, and Tonnage
        # Import the cruise_ships.csv DataFrame and assign it to
        # a cruise_ships variable

        cruise_ships = pd.read_csv("cruise_ships.csv")

        # Extract the "Operator" column from the DataFrame
        # and assign it to an "operators" variable.

        operators = cruise_ships["Operator"]

        # Extract the "Tonnage" column from the DataFrame
        # and assign it to an "tonnages" variable.

        tonnages = cruise_ships["Tonnage"]

        # Extract the "Name" column from the DataFrame
        # and assign it to an "cruise_names" variable.
    
        cruise_names = cruise_ships["Name"]
        



# Select two or more columns from a Dataframe

    nba = pd.read_csv("nba.csv")
    nba
    
    # Pull the name and teams columns
    nba(["Name", "Team"])


    # Excercise 19
    
        import pandas as pd
        # This challenge includes a "chicken_restaurants.csv" dataset with 6 columns:
        # Name, Original Location, Year, Headquarters, Locations, Areas Served
        # Import the CSV into a DataFrame and assign it to a "chicken" variable.

        chicken = pd.read_csv("chicken_restaurants.csv")

        # Extract the "Year" and "Locations" columns (in that order) into
        # their own DataFrame. Assign the DataFrame to a "years_and_locations" variable.
        years_and_locations = chicken(["Year", "Locations"])
        
        # Extract the "Locations", "Name", and "Headquarters" columns (in that order)
        # into their own DataFrame. Assign the DataFrame to a 
        # "interesting_facts" variable.
        interesting_facts = chicken[["Locations", "Name", "Headquarters"]]
   


# Add a New Column, Add a New Column From Existing Column, Review of value_counts, and Drop Dataframe Rows With Null Values with dropna Method

    nba = pd.read_csv("nba.csv")
    nba
    
    # Add a column called Sport with value Basketball
    nba["Sport"] = "Basketball
    
    # Insert between Number and Positions Column. the number below represents where it show be as in 3 column (fourth since we start at zero)
    nba.insert(loc = 3, column = "Sport", value = "Basketball")
    
    # Create from an existing column
    # Add 10 years to the age column
    
    nba["Age in a Decade"] = nba["Age"] + 10
    nba["Age in a Decade"] = nba["Age"].add(10)
    
    # Review of value_counts
    # Returns unique values in dataframes and how often
    
    nba.value_counts()
    
    # Most frequent positions
    
    nba["Positions"].value_counts()
    
    # Drop Rows With Null Values
    # Marks missing values as NaN
    
    # Remove rows with a missing value in ANY part of the row
    
    nba.dropna()
    nba.dropna(how = "any")
    
    # Now remove rows where it's ALL missing/null/NaN
    
    nba.dropna(how = "all")
    
    # Remove any rows where the column "College" has a missing value
    
    nba.dropna(subset = ["College"])
    
    # Excercise 20
         
        # The data.csv file contains a dataset of random numbers.
        # The dataset has 4 columns: A, B, C, and D.
        # Import pandas and use it to parse the CSV.
        # Assign the imported DataFrame to a variable called 'data'.
       
        import pandas as pd 
        data = pd.read_csv("data.csv")


        # Filter the dataset to remove rows where ALL the
        # values are missing. Assign the resulting DataFrame
        # to a "no_empty_rows" variable.
        
        no_empty_rows = data.dropna(how = "all")


        # Filter the dataset to remove rows that have a missing value
        # in either the "B" or "D" columns.
        # Assign the resulting DataFrame to a "result" variable.
        
        result = data.dropna(subset = ["B", "D"])
        
  
  
  
# Fill in the Missing Dataframe Values With The Fillna Method, Astype Method 1, Astype Method 2

    nba = pd.read_csv("nba.csv").dropna{how = "all"}
    nba
    
    # Fill any NaN with a zero
    nba.fillna(0)
    
    # Fill any NaN value in a College column. NOTE these created a new series but not in the dataframe
    nba["College"].fillna("Unknown")
    
    # Add a permanent change, use inplace method OR reassign it to itself
    nba["College"].fillna("Unknown", inplace = True)
    nba["College"] = nba["College"].fillna("Unknown")
    #Another way example
    nba["College"] = nba["College"].fillna(value = 0)
    
    # Astype Method
    # NOTE even if there is one missing numeric value, pandas converts it to floating points
    
    # Tells you if you have any Nan values in set    
    nba["Age"].hasnans
    
    # Convert Floats to Int (2 ways)
    nba["Age"].astype("int")
    nba["Age"].astype(int)
    
    # How to find the number of unique values in a column
    nba["Position"].nunique()
    
    # Creates each unique value in a row at the bottom
    nba["Position"].astype("category")
    
    # Excercise 21
         
        # Import the health.csv file and assign it to a 'health' variable.
        # The resulting DataFrame will have 3 columns: Weight, Height, and Blood Type
        # Convert the values in the Weight Series to strings and overwrite the original column
        # Convert the values in the Height Series to integers and overwrite the original column
        # Convert the values in the Blood Type Series to categories and overwrite the original column
        
        health = pd.read_csv("health.csv")
        health["Weight"] = health["Weight"].astype(str)
        health["Height"] = health["Height"].astype(int)
        health["Blood Type"] = health["Blood Type"].astype("category")
    
    
    
# Sort Dataframe With Sort_Values Method 1 & 2

    nba = pd.read_csv("nba.csv")
    
    # Sort by column "Name"
    nba.sort_values("Name")
    nba.sort_values(by = "Name")
    nba.sort_values(by = "Name", ascending = True)
    
    # When Sorting, NaN is behind largest values, so how to cluster towards the front
    nba.sort_values("Salary", na_positions = "first")
    
    # Sort by using more than one column
    
    nba = pd.read_csv("nba.csv").dropna(how = "all")
    
    # How to sort the teams and then the players by each team
    nba.sort_values(by = ["Team", "Name"])
    nba.sort_values(by = ["Team", "Name"], ascending = True)
    
    # How to sort the teams and then the players by each team in REVERSE
    nba.sort_values(by = ["Team", "Name"], ascending = [True, False])
    
    nba.sort_values(by = ["Team", "Name"], ascending = [True, False])
    
    
    # Excercise 22
         
        import pandas as pd 

        # This challenge includes a s&p500.csv with 6 columns: 
        # Symbol, Security, Sector, Industry, HQ, Founded
        # Import the s&p500.csv DataFrame and assign it to
        # a companies variable.
        
        companies = pd.read_csv("s&p500.csv")

        # Sort the DataFrame by the values in the "Industry" column in ascending order
        # Assign the new DataFrame to a "by_industry" variable.
        
        by_industry = companies.sort_values("Industry", ascending = True)

        # Sort the DataFrame by the values in the "HQ" column in descending order
        # Assign the new DataFrame to a "by_headquarters_descending" variable.
        
        by_headquarters_descending = companies.sort_values("HQ", ascending = False)

        # Sort the DataFrame by two conditions:
        #  - by the values in the "Sector" column in descending order
        #  - THEN by the values in the "Security" column in ascending order
        # Assign the new DataFrame to a 'by_sector_and_security' variable
        
        by_sector_descending = companies.sort_values(by = ["Sector", "Security"] ascending = [False, True])
    
    
    
 
# Sort DataFrame Index With The Rank Method & Rank Series Values With The Rank Method

    nba = pd.read_csv("nba.csv").dropna(how = "all")
           
    # Want to organize by Index
    nba.sort_index()
    nba.sort_index(ascending = True)
    
    # How to assign the highest salary in our set to be ranked one
    # First converting NaN's to 0
    nba["Salary"] = nba["Salary"].fillna(0).astype("int")
    
    nba["Salary Rank"] =nba["Salary"].rank(ascending = False).astype("int")
    nba.sort_values("Salary", ascending = False)
    
    
    
    
    
    
############SECTION 3   
    
    
    
    
# Module's Dataset & Memory Optimization
    
    df = pd.read_csv("employees.csv", parse_dates = ["Start Date", "Last Login Time"])
    df["Senior Management"] = df["Senior Management"].astype("bool")
    df["Gender"] = df["Gnder"].astype("category")
    

    # Filter a Dataframe Based on a Condition
    
    # The first df would do boolean while the second df create a dataframe with the items that match
    df[df["Gender"] == "Male"]
    
    # mask saves the boolean series that gets generated
    mask = df["Team"] == "Finance"
    df[mask]
    
    # If column has boolean just do this
    df[df["Senior Management"]]
    
    # Not Equal
    df["Team"] != "Marketing"
    
    # <= for dates mean prior to
    
    # Excercise 23
         
        import pandas as pd 

        # This challenge includes a the_office.csv dataset.
        # It is a listing of all episodes in the popular American sitcom The Office.
        # The dataset has 7 columns:
        # Season, Episode, Name, Director, Writer, Airdate, Viewership
        # Import the the_office.csv fille into a DataFrame. 
        # Tell pandas to parse the values in the Airdate column as datetime values.
        # Finally, assign the imported DataFrame to an 'office' variable.
        office = pd.read_csv("the_office.csv", parse_dates = ["Airdate"])


        # CHALLENGE 1:
        # Find all episodes with a Writer of "Greg Daniels"
        # Assign the resulting DataFrame to a 'written_by_greg' variable.
        written_by_greg = office[office["Writer"] == "Greg Daniels"]


        # CHALLENGE 2:
        # Find all episodes BEFORE season 8 (not including season 8)
        # Assign the resulting DataFrame to a 'good_episodes' variable
        good_episodes = office[office["Season"] < 8]


        # CHALLENGE 3:
        # Find all episodes that aired before 1/1/2008.
        # Assign the resulting DataFrame to an 'early_episodes' variable.
        early_episodes = office[office["Airdate"] < "1/1/2008"]
 
 
# Filter With More Than One Condition (AND - &)

    # AND OR
    mask1 = df["Gender"] == "Male"
    mask2 = df["Team"] == "Marketing"
    
    df[mask1 & mask2]
    
    # Excercise 24
         
        import pandas as pd 
        # This challenge includes a the_office.csv dataset.
        # It is a listing of all episodes in the popular American sitcom The Office.
        # The dataset has 7 columns:
        # Season, Episode, Name, Director, Writer, Airdate, Viewership
        # Import the the_office.csv file into a DataFrame. 
        # Tell pandas to parse the values in the Airdate column as datetime values.
        # Finally, assign the imported DataFrame to an 'office' variable.
        office = pd.read_csv("the_office.csv", parse_dates = ["Airdate"])


        # CHALLENGE 1:
        # Find all episodes with a Viewership greater than 10
        # who are also directed by Jeffrey Blitz
        # Assign the resulting DataFrame to a 'jeffs_episodes' variable.
        good_viewership = office["Viewership"] > 10
        directed_by_jeff = office["Director"] == "Jeffrey Blitz"
        jeffs_episodes = office[good_viewership & directed_by_jeff]

        # CHALLENGE 2:
        # Find all episodes in season 5 that have an episode number
        # greater than or equal to 13.
        # Assign the resulting DataFrame to a "second_half_of_season_5" variable.
        season_5 = office["Season"] == 5
        episodes_13_and_up = office["Episode"] >= 13
        second_half_of_season_5 = office[season_5 & episodes_13_and_up]

        # CHALLENGE 3:
        # Find all episodes that were the 6th episode of their season
        # and also aired before 01/01/2010.
        # Assign the resulting DataFrame to a "sixth_episodes_of_early_seasons" variable.
        sixth_episodes = office["Episode"] == 6
        desired_airdate = office["Airdate"] < "01/01/2010"
        sixth_episodes_of_early_seasons = office[sixth_episodes & desired_airdate]
        

# Filter With More Than One Condition (OR - |)
    
    #
    mask1 = df["Senior Management"]
    mask2 = df["Start Date"] < "1990-01-01"
    df[mask1 | mask2]
    
    # Can do multiple
    df[(mask1 & mask2) | mask3]
    
    # Excercise 25
         
        import pandas as pd 
        # This challenge includes a the_office.csv dataset.
        # It is a listing of all episodes in the popular American sitcom The Office.
        # The dataset has 7 columns:
        # Season, Episode, Name, Director, Writer, Airdate, Viewership
        # Import the the_office.csv file into a DataFrame. 
        # Tell pandas to parse the values in the Airdate column as datetime values.
        # Finally, assign the imported DataFrame to an 'office' variable.
        office = pd.read_csv("the_office.csv", parse_dates = ["Airdate"])


        # CHALLENGE 1:
        # Find all episodes that were EITHER in Season 4
        # OR directed by Harold Ramis
        # Assign the resulting DataFrame to a 'season_4_or_harold' variable.
        
        season_4 = office["Episode"] == 4
        harold = office["Director"] == "Harold Ramis"
        season_4_or_harold = office[season_4 | harold]

        # CHALLENGE 2:
        # Find all episodes that EITHER had a Viewership less than 4
        # OR aired on/after January 1st, 2013.
        # Assign the resulting DataFrame to a 'low_viewership_or_later_airdate' variable.
        
        viewership = office["viewership"] < 4
        airdate = office["Airdate"] >= "01-01-2013"
        low_viewership_or_later_airdate = office[viewership | airdate]

        # CHALLENGE 3:
        # Find all episodes that EITHER the 9th episode of their season
        # OR had an episode Name of "Niagara"
        # Assign the resulting DataFrame to a 'ninth_or_niagara' variable.
        ninth_episodes = office["Episode"] == 9
        niagara = office["Name"] == "Niagara"
        ninth_or_niagara = office[ninth_episodes | niagara]
        
        
        
# Check For Inclusion With The Isin Method

    mask1 = df["Team"] == "Legal"
    mask2 = df["Team"] == "Sales"
    mask3 = df["Team"] == "Product"
    df[mask1 | mask2 | mask3]
    
    # Runs to see if each term is in the row and return bool
    mask = df["Team"].isin(["Legal", "Sales", "Product"])
    df[mask]
    
    # Excercise 26
         
        import pandas as pd 
        # This challenge includes a billboard.csv dataset.
        # It is a list of the top-selling albums of all time according to Billboard
        # The dataset has 5 columns:
        # Artist,Album,Released,Genre,Sales
        # Import the billboard.csv fille into a DataFrame. 
        # Assign the imported DataFrame to an 'billboard' variable.
        billboard = pd.read_csv("billboard.csv")

        # CHALLENGE 1
        # Find all records with an Artist of either Michael Jackson,
        # Whitney Houston, or Celine Dion. Assign the resulting 
        # DataFrame to a "trios" DataFrame.
        target_artists = billboard["Artist"].isin(["Michael Jackson", "Whitney Houston", "Celine Dion"])
        trios = billboard[target_artists]

        # CHALLENGE 2
        # Find all records with Sales of either 25, 35, or 45
        # million copies. Note that the 'Sales' column's integers
        # reflect album sales in millions. Assign the resulting DataFrame
        # to a 'fives' DataFrame
        target_sales = billboard["Sales"].isin([25, 35, 45])
        fives = billboard[target_sales]

        # CHALLENGE 3
        # Find all records released in either 1979, 1989, or 1999.
        # Assign the resulting DataFrame to a 'end_of_decade' DataFrame.
        target_years = billboard["Released"].isin([1979, 1989, 1999])
        end_of_decade = billboard[target_years]
        
        
        
# Check For Null and Present Dataframe Values With The Isnull and NotNull Method, and Check For Inclusion With The Between Method
    
    # bool for looking at Null values
    mask = df["Team"].isnull()
    df[mask]
    
    # NotNull is opposite
    condition = df["Gender"].notnull()
    df[condition]
    
    # Find Between
    df[df["Salary"].between(60000, 70000)]
    df[df["Bonues %"].between(2.0, 5.0)]
    df[df["Start Date"].between("1991-01-01", "1992-01-01")]
    
    # Excercise 27
         
        import pandas as pd 
        # This challenge includes a billboard.csv dataset.
        # It is a list of the top-selling albums of all time according to Billboard
        # The dataset has 5 columns:
        # Artist,Album,Released,Genre,Sales
        # Import the billboard.csv fille into a DataFrame. 
        # Assign the imported DataFrame to an 'billboard' variable.
        weather = pd.read_csv("weather.csv", parse_dates = ["Day"])

        # CHALLENGE 1
        # Find all records with an Artist of either Michael Jackson,
        # Whitney Houston, or Celine Dion. Assign the resulting 
        # DataFrame to a "trios" DataFrame.
        target_week = weather["Day"].between("04/15/2022", "04/22/2022")
        week_of_weather = weather[target_week]

        # CHALLENGE 2
        # Find all records with Sales of either 25, 35, or 45
        # million copies. Note that the 'Sales' column's integers
        # reflect album sales in millions. Assign the resulting DataFrame
        # to a 'fives' DataFrame
        low_temp_target = weather["Low Temp"].between(30, 50)
        cold_days = weather[low_temp_target]

        # CHALLENGE 3
        # Find all records released in either 1979, 1989, or 1999.
        # Assign the resulting DataFrame to a 'end_of_decade' DataFrame.
        high_temp_target = weather["High Temp"].between(50, 75)
        warm_days = weather[high_temp_target]
        
        
        
# Check For Duplicate Dataframes Rows With The Duplicated Method, Delete Duplicate Dataframe Rows With The drop_duplicates Method, and Identify and Count Unique Values With The Unique and Nunique Methods 
        
    
    df = pd.read_csv("employees.csv", parse_dates = ["Start Date", "Last Login Time"])
    df["Senior Management"] = df["Senior Management"].astype("bool")
    df["Gender"] = df["Gender"].astype("category")
    df.sort_values("First Name", inplace = True)
    
    # Check For Duplicate Dataframes Rows With The Duplicated Method
    
    # Doesn't mark the first occurance as duplicate, but the rest will
    df[df["First Name"].duplicated()]
    
    # Doesn't mark the last occurance as duplicate, but the rest will
    df[df["First Name"].duplicated(keep = "last")]
    
    # Removes all duplicates
    df[df["First Name"].duplicated(keep = False)]
    
    # ~ Keeps all unique names
    mask = ~df["First Name"].duplicated(keep = False)
    
    # Drop_duplicates method
    # Drops it if the whole rows is the same
    
    # keeps the first of the duplicates
    df.drop_duplicates(subset = ["First Name"], keep = "first")
    
    # Removes all duplicates
    df.drop_duplicates(subset = ["First Name"], keep = False)
    
    # Across mulitple rows essentially AND
    df.drop_duplicates(subset = ["First Name","Team"])
    
    # Doesn't change original dataset unless
    df.drop_duplicates(subset = ["First Name","Team"], inplace = True)
    
    # Unique and Nunique Methods
    
    df = pd.read_csv("employees.csv", parse_dates = ["Start Date", "Last Login Time"])
    df["Senior Management"] = df["Senior Management"].astype("bool")
    df.sort_values("First Name", inplace = True)
    
    # Shows all unique values
    df["Gender"].unique()
    
    # Provides number of unique items
    len(df["Gender"].unique())
    
    # Another way of doing above
    # NOTE Nunique does not count null
    df["Gender"].nunique()
    
    # Produces same value as len equation
    df["Gender"].nunique(dropna = False)
    
 
 
 
############SECTION 4
    
    
# Dataframes 3 Module & Ipmort Dataset

    # Set_index & Reset_Index Methods
    bond = pd.read_csv("jamesbond.csv"), index_col = "Film")
    
    # How to create a index for your dataframe
    bond.set_index(keys = "Film"), inplace = True)
    
    # How to reset
    bond.reset_index()
    bond.reset_index(drop = True)
    
    # Back to Original
    bond.reset_index(drop = False, inplace = True)
    
    # set_index replaces the index so here is how to keep it
    bond.reset_index(inplace = True)
    bond.set_index("Year", inplace = True)
    
    # Retrieve Rows by Index Label with .Loc Accessor
    bond = pd.read_csv("jamesbond.csv"), index_col = "Film")
    bond.sort_index(inplace = True)
    
    # Show the movies facts 
    bond.loc["Goldfinger"]
    bond.loc["GoldenEye"]
    
    # Can have duplicates, more than one returns a dataframe
    bond.loc["Casino Royale"]
    
    #How to get part of a list and includes BOTH items
    bond.loc["Diamonds Are Forever":"From Russia with Love"]
    
    # Can jump over rows with 2
    bond.loc["Diamonds Are Forever":"From Russia with Love":2]
    
    # Retrieve Rows by Index Position with Iloc Accessor
    # I in Iloc is Index
    # Starts counting at zero
    bond.iloc[0]
    
    # More than one row
    bond.iloc[[15, 20]]    
    
    # Includes 4 but not row 8
    bond.iloc[4:8]

    # Second Arguements to Loc and Iloc Accessors
    bond = pd.read_csv("jamesbond.csv"), index_col = "Film")
    bond.sort_index(inplace = True)
    
    # Get the actor in the movie
    bond.loc["Moonraker", "Actor"]
    
    # Provide multiple columns, this below gets director and box office from Moonraker
    bond.loc["Moonraker", ["Director", "Box Office"]]
    
    #Same as above but now two movies
    bond.loc[["Moonraker", "A View to a Kill"], ["Director", "Box Office"]]
    
    # all columns between
    bond.loc[["Moonraker": "Thunderball"], ["Director":"Budget"]]  
    
    # Set New Value For a Specific Cell or Cells in a Row
    

    
   
   
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    



